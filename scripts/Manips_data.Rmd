---
title: "Nettoyage et enrichissement des données HAL"
subtitle: "Désambiguïsation des intitulés de conférences"
output:
  html_document:
    #self_contained: false
    theme: paper
    toc: yes
    toc_float: yes
    #code_folding: hide
    includes:
      in_header: header.html
      after_body: footer.html
      
knit: (
  function(inputFile, encoding) { 
    
    rmarkdown::render(inputFile, params = "ask",  
      encoding    = encoding,
      output_dir = "../notebook",
      output_file = "Synthese.html") })
---

<style>
body {
text-align: justify;
#background: #f9f9f9;
}
</style> 

```{r setup, include=FALSE}
# Settings summarytools
library(summarytools)
st_options(plain.ascii = FALSE,               # This is very handy in all Rmd documents
           style = "rmarkdown",               # This too
           footnote = NA,                    # Avoids footnotes which would clutter the results
           subtitle.emphasis = FALSE
         # This is a setting to experiment with - according to the theme used, it might improve the headings layout
)
# General settings      
knitr::opts_chunk$set(
	eval = TRUE,
	echo = FALSE,
	fig.align = "center",
	fig.show = "hold",
	message = FALSE,
	warning = FALSE,
	collapse = TRUE,
	results = 'asis', # important dfSummary
	out.width = "100%"
)
```


----

```{r librairies et données, cache=FALSE, include=FALSE}
# Packages nécessaires à l'analyse
packages = c("tidyverse", "summarytools", "threadr", "rvest", "fuzzyjoin", "tm", "plotly")

## Installation des packages si besoin et chargement des librairies
package.check <- lapply(packages,
  FUN = function(x) {
      if (!require(x, character.only = TRUE)) {
      install.packages(x, dependencies = TRUE)  #remotes::install_github("skgrange/threadr")
      library(x, character.only = TRUE)}})


# Import données 

    # HAL (format bibTex)
hal1 <- read_bibtex("https://api.archives-ouvertes.fr/search/?q=+publicationDateY_i%3A[2018+TO+2020]+AND++(docType_s%3ACOMM)&fq=collCode_s%3AINRIA2&rows=100000&wt=bibtex")
hal2 <- read_bibtex("https://api.archives-ouvertes.fr/search/?q=+publicationDateY_i%3A[2021+TO+2022]+AND++(docType_s%3ACOMM)&fq=collCode_s%3AINRIA2&rows=100000&wt=bibtex")
hal <- rbind(hal1 %>% select(bibtex_key, article_type, title, author, url, editor, series, volume, number, pages, year, month, keywords, pdf, hal_id, hal_version, publisher, doi, organization, booktitle, address ), 
              hal2 %>% select(bibtex_key, article_type, title, author, url, editor, series, volume, number, pages, year, month, keywords, pdf, hal_id, hal_version, publisher, doi, organization, booktitle, address )) %>% 
    distinct() %>% 
    filter(year >= 2018 & year <= 2022)# plus de 10.000 communications
# Sauvegarde du nombre de communications sans hal_id
a <- hal %>% filter(is.na(hal_id)) %>% nrow()
# Reconstruction d'un id pour les communications n'en ayant pas
hal <- hal %>% mutate(hal_id = case_when(is.na(hal_id) ~ substr(url, nchar(url)-12+1, nchar(url)), TRUE ~ hal_id))
    
    # CORE (CSV)
core <- purrr::map(
        .x = (as.data.frame(rep(1:45, each = 1)) %>% rename(page = `rep(1:45, each = 1)`))$page,
        .y = data.frame(matrix(ncol = 1, nrow = 1)),
        .f = ~read_html(paste0("http://portal.core.edu.au/conf-ranks/?search=&by=all&source=all&sort=atitle&page=", .x)) %>% html_nodes('body')  %>% html_nodes('table') %>% html_table(dec = ","), 
        .default = NA)
core <- bind_rows(core) %>% rename(title = Title) %>% 
    mutate_all(na_if,"") %>% 
    mutate(core_id = row_number()) # 2.212 conférences
```


**Objectif** : Désambiguïsation des intitulés de conférences renseignés dans les données HAL, en se basant sur le référentiel CORE

**Dernière mise à jour** : `r format(Sys.time(), '%d %B %Y')`

**Données à nettoyer** : 

- **Sources des données** : [API HAL](https://api.archives-ouvertes.fr/docs) requêtée sur les références de la collection HAL Inria de type COMM publiées entre 2018 et 2022 
- **Dimensions** : `r ncol(hal)` variables et `r nrow(hal)` individus

**Données de référence** : 

- **Sources des données** : [CORE Conference Portal](http://portal.core.edu.au/conf-ranks/)
- **Dimensions** : `r ncol(core)` variables et `r nrow(core)` individus


---

# Résumé des bases{.tabset}

## HAL

L'identifiant unique (*hal_id*) est récupéré depuis le champ *url*, et imputé aux `r a` communications n'ayant pas d'identifiant à l'import des données de l'archive ouverte.

```{r}
dfSummary(hal, style = "grid", graph.magnif = 1, valid.col = FALSE, varnumbers = FALSE, tmp.img.dir = "/tmp", max.distinct.values = 5, headings=FALSE, method = "render")
```

<br>

-----------------------------


## CORE

```{r}
dfSummary(core, style = "grid", graph.magnif = 1, valid.col = FALSE, varnumbers = FALSE, tmp.img.dir = "/tmp", max.distinct.values = 5, headings=FALSE, method = "render")
```

<br>

-----------------------------

# 1. Désambiguïsation des intitulés de conférence

<br>

```{r}
# Nettoyage des données
    # HAL
hal_manip <- hal %>% rename(hal_title = title) %>% 
    mutate(booktitle = str_replace_all(booktitle, "[[:punct:]]", " "), # retrait de tous les caractères spéciaux
           booktitle = tolower(booktitle), # minuscules
           booktitle = str_replace(booktitle, "  ", " ")) # retrait des doubles espaces
    # CORE
core_manip <- as.data.frame(gsub("[[:punct:]]", "", as.matrix(core))) %>%  # retrait de tous les caractères spéciaux
    mutate(core_title = tolower(title), # minuscules
           core_title = str_replace(core_title, "  ", " "), # retrait des doubles espaces
           core_acronym = tolower(Acronym), # même chose pour l'acronyme qui servira de colonne de jointure dans un second temps
           core_acronym = str_replace(core_acronym, "  ", " "),
           nb_car_acronym = str_count(Acronym, '\\w+')) # nombre de mots par acronyme
```


Afin de maximiser le matching des intitulés de conférences, un travail de nettoyage et de lémmatisation est préalablement effectué. Les intitulés sont ainsi mis en minuscules, sans accents et sans caractères spéciaux. Un match est opéré 2 fois pour faire correspondre les intitulés des données du HAL avec ceux du référentiel CORE. 

Dans un premier temps, les chaînes de caractères formant l'intitulé des conférences HAL sont matchées avec celles du CORE, à partir de quoi on obtient une distance correspondant au nombre de caractères **qui ne sont pas communs** au 2 intitulés (si l'intitulé est exactement le même, la distance sera donc de 0). Cette manipulation est réalisée sur la variable HAL *booktitle*, matchée avec la variable CORE *title* indiquant l'intitulé des conférences.

Dans un deuxième temps ce sont seulement les acronymes qui sont matchés entre les données HAL et le référentiel CORE. Ces derniers sont extraits du nom de conférence disponible dans le champ "*booktitle*" des données HAL. La jointure se fait cette fois sur une base de match **exact**, contrairement aux manipulations réalisées en premier sur les intitulés des conférences. Ainsi, lorsque l'acronyme extrait du titre disponible dans les données HAL correspond à l'acronyme CORE, les informations du référentiel sont récupérées et viennent enrichir les données HAL. 

<br>

## Match par distance entre les chaînes de caractères (score)

<br>

Pour chaque communication HAL, une jointure approximative est effectuée sur les noms de conférences, en utilisant la méthode '*Optimal string aligment*' qui ne récupère que le match le plus proche du champ à enrichir. Dans le cas où 2 noms de conférences ont la même distance par rapport au nom CORE, les 2 conférences sont gardées dans les données enrichies, et devront alors faire l'objet d'un traitement manuel.

Les intitulés originaux des communications et conférences des 2 sources de données sont réinjectés dans les données, à la place des intitulés lémmatisés.

Dans la table ci-dessous, les colonnes *hal_title* à *booktitle* proviennent de HAL ; les colonnes *core_title* à *Primary FoR* proviennent de CORE ; les colonnes *distance*, *part_similarite* et *method* sont générées par l'algorithme de comparaison.

<br>

```{r}
# Match inexact avec distance
enriched_hal_score <- stringdist_left_join(hal_manip %>% select(hal_title, year, hal_id, booktitle) %>% filter(!is.na(booktitle)),
                                           core_manip %>% select(core_title, Acronym, core_id, Source, Rank, `Primary FoR`),
                                           by = c("booktitle" = "core_title"),
                                           max_dist = 350,
                                           distance_col = "distance") %>% 
    mutate(method = "score") %>% 
    arrange(distance) %>% 
    group_by(hal_id) %>% 
    slice_min(order_by = distance, n = 1) %>%  # ne garder que le match le plus proche
    ungroup() %>% rowwise() %>% 
    # calcul du pourcentage de similarité
    mutate(nb_common_char = sum(!is.na(pmatch(unlist(strsplit(booktitle,"")), unlist(strsplit(core_title,"")), duplicates.ok = F))),
           part_similarite = round(nb_common_char / nchar(booktitle) * 100, 2)) %>% 
    select(-nb_common_char)


# On remet les noms initiaux (avec caractères spéciaux et majuscules)
enriched_hal_score <- enriched_hal_score %>% 
    # Noms des communications et conférences dans HAL
    select(-c(hal_title, booktitle)) %>% 
    left_join(., hal %>% select(title, booktitle, hal_id), by = "hal_id") %>% 
    rename(hal_title = title) %>% 
    # Noms des conférences et acronymes dans CORE
    select(-c(core_title, Acronym)) %>% mutate(core_id = as.numeric(core_id)) %>% 
    left_join(., core %>% select(title, core_id, Acronym), by = "core_id") %>% 
    rename(core_title = title) %>% 
    # Mise en forme finale
    select("hal_title","year","hal_id","booktitle","core_title","Acronym","Source","Rank","Primary FoR","distance","part_similarite","method")

# Stats
diff1 <- setdiff(hal$hal_id, enriched_hal_score$hal_id)
na_booktitle <- hal %>% filter(is.na(booktitle))
diff2 <- setdiff(diff1, na_booktitle$hal_id)
```



```{r echo=FALSE, warning=FALSE, error=FALSE}
DT::datatable(enriched_hal_score, options=list(pageLength=25, searching=T, scrollX='400px'))
```

Cette première méthode de jointure non exacte sur les intitulés de conférences a permis d'enrichir `r n_distinct(enriched_hal_score$hal_id)` communications sur `r nrow(hal)`, soit `r round(n_distinct(enriched_hal_score$hal_id) / nrow(hal) *100, 2)`%. Les `r hal %>% filter(is.na(booktitle)) %>% nrow()` communications restantes n'ont pas pu être enrichies faute d'une valeur renseignée dans le champ '*booktitle*'.
Parmi les communications enrichies, `r enriched_hal_score %>% filter(distance == 0) %>% nrow()` sont exactes, c'est-à-dire que l'intitulé dans les données HAL correspond **exactement** à celui de la conférence dans les données CORE (aux caractères spéciaux et majuscules près). 


----

<br>


## Match par mot commun aux deux chaînes de caractères (token) 

<br>

La deuxième jointure est réalisée en identifiant l'acronyme qui se trouve typiquement dans l'intitulé de conférence des données HAL, pour le matcher avec les données CORE. Lorsque l'acronyme identifié **se retrouve à l'identique** dans le champ *Acronym* de CORE, alors l'entrée est enrichie du référentiel CORE. L'extraction de l'acronyme est faite de deux manières à partir du champ *booktitle* des données HAL :

* le premier mot est extrait (excepté s'il s'agit d'un des 3 mots suivants : IEEE, ACM, SIAM qui sont des sociétés savantes organisant de nombreuses conférences) ;
* le ou les mots entièrement en majuscules sont extraits ;
* un arbitrage est effectué entre les 2 valeurs récupérées, selon un ensemble de règles implémentées dans le script ci-dessous.

```{r eval=F, echo=T}
# règle pour arbitrer entre premier mot ou mot en capitales
hal_acronym = case_when(is.na(capital_word) ~ first_word,
                        is.na(first_word) ~ capital_word,
                        first_word == "In" ~ capital_word, #cas particulier où "In" ne correspond pas à l'acronyme de la conf
                        first_word == capital_word ~ first_word,
                        str_detect(first_word, "[0-9]") == TRUE ~ capital_word, #qd first_word contient un chiffre
                        nchar(capital_word) == 1 ~ first_word, #qd 1 seul caractère dans capital_word
                        grepl('[^[:alnum:]]', first_word) ~ capital_word, #qd first_word contient des caractères spéciaux (hors lettres et digits)
                        TRUE ~ capital_word)  #dans les autres cas on garde le mot en lettre capitales car plus fiable
```



Après jointure des acronymes extraits des noms de conférences HAL avec les données du CORE, les données sont réharmonisées avec les bases initiales pour récupérer les intitulés et acronymes non lemmatisés. 

<br>

```{r}
        #--------- PREMIÈRE PASSE DE JOINTURE TOKEN


# Fonction pour retirer les mots doublons
rem_dup_word <- function(x){
paste(unique(trimws(unlist(strsplit(x,split=" ",fixed=F,perl=T)))),collapse = 
" ")
}

# Extraction de l'acronyme depuis booktitle
hal_manip_token <- hal %>% rowwise() %>% 
    mutate(booktitle = removeWords(booktitle, c("IEEE ", "ACM ", "SIAM ")), #on retire ces 3 acronymes
           first_word = word(booktitle, 1), #premier mot du string
           capital_word = rem_dup_word(sapply(str_extract_all(booktitle, "\\b[A-Z]+\\b"), paste, collapse= ' ')), #mots en lettres capitales uniques
           capital_word = gsub("\\W*\\b\\w\\b\\W*", " ", capital_word)) %>% #on retire les lettres toutes seules (ex: "E" extrait de "E-health")
    mutate_all(na_if, "") %>% #on remplace les valeurs vides par de vrais NAs
    # règle pour arbitrer entre premier mot ou mot en capitales
    mutate(hal_acronym = case_when(is.na(capital_word) ~ first_word,
                                    is.na(first_word) ~ capital_word,
                                    first_word == "In" ~ capital_word, #cas particulier où "In" ne correspond pas à l'acronyme de la conf
                                    first_word == capital_word ~ first_word,
                                    str_detect(first_word, "[0-9]") == TRUE ~ capital_word, #qd first_word contient un chiffre
                                    nchar(capital_word) == 1 ~ first_word, #qd 1 seul caractère dans capital_word
                                    grepl('[^[:alnum:]]', first_word) ~ capital_word, #qd first_word contient des caractères spéciaux (hors lettres et digits)
                                    TRUE ~ capital_word)) %>%  #dans les autres cas on garde le mot en lettre capitales car plus fiable
    select(title, booktitle, year, hal_id, hal_acronym) %>% 
    rename(hal_title = title)

# Lémmatisation des acronymes 
hal_manip_token <- hal_manip_token %>%  
    mutate(hal_acronym = str_replace_all(hal_acronym, "[[:punct:]]", " "), # retrait de tous les caractères spéciaux
           hal_acronym = tolower(hal_acronym)) %>%  # minuscules
    mutate(hal_acronym = strsplit(as.character(hal_acronym), " ")) %>% unnest(hal_acronym) %>%  #split par ligne les acronymes multiples
    mutate_all(na_if, "") %>% 
    mutate_all(na_if, " ") %>% 
    filter(hal_acronym != "ieee",
           hal_acronym != "acm")

# Match sur les tokens communs
enriched_hal_token <- hal_manip_token %>% 
    filter(!is.na(hal_acronym)) %>% 
    left_join(., 
              core_manip %>% select(core_title, core_acronym, Acronym, core_id, Source, Rank, `Primary FoR`), 
              by = c("hal_acronym" = "core_acronym")) %>% 
    filter(!is.na(Acronym)) %>% 
    mutate(method = "token") %>% 
    select("hal_title","year","hal_id","booktitle","core_title","Acronym","Source","Rank","Primary FoR","method","core_id")

# On remet les colonnes initiales (non lémmatisés)
enriched_hal_token <- enriched_hal_token %>% 
    # Noms des communications et conférences dans HAL
    select(-c(hal_title, booktitle)) %>% 
    left_join(., hal %>% select(title, booktitle, hal_id), by = "hal_id") %>% 
    rename(hal_title = title) %>% 
    # Noms des conférences et acronymes dans CORE
    select(-c(core_title, Acronym)) %>% mutate(core_id = as.numeric(core_id)) %>% 
    left_join(., core %>% select(title, core_id, Acronym), by = "core_id") %>% 
    rename(core_title = title) %>% 
    # Mise en forme finale
    select("hal_title","year","hal_id","booktitle","core_title","Acronym","Source","Rank","Primary FoR","method") %>% 
    mutate(distance = NA_real_, .before = "method") %>%  #colonne distance vide pour token avant rbind 
    mutate(part_similarite = NA_real_, .before = "method") #colonne distance vide pour token avant rbind 
```


```{r echo=FALSE, warning=FALSE, error=FALSE}
DT::datatable(enriched_hal_token, options=list(pageLength=25, searching=T, scrollX='400px'))
```


Cette deuxième méthode de jointure exacte par match de l'acronyme CORE, a permis d'enrichir `r n_distinct(enriched_hal_token$hal_id)` communications sur `r nrow(hal)`, soit `r round(n_distinct(enriched_hal_token$hal_id) / nrow(hal) *100, 0)`%.


<br>


## Données HAL enrichies

<br>

```{r}
# On remet avec la jointure par distance
    # Traitement général
enriched_hal <- rbind(enriched_hal_score, enriched_hal_token) %>% distinct() %>%
    mutate(is_token = case_when(method == "token" ~ 1, TRUE ~ 0)) %>% 
    group_by(hal_id) %>% mutate(nb_matchs = n(), #nb de résultats via token ou score par comm
                                nb_token = sum(is_token), # nb de résultats via token par comm
                                is_token_match = case_when(any(method == "token") ~ 1, TRUE ~ 0), #la communication a-t-elle au moins un match par token ?
                                is_score_0 = case_when(any(distance == 0) ~ 1, TRUE ~ 0), #la communication a-t-elle au moins un score à 0 ?
                                id_core = paste(core_title, Acronym, sep = "-"), # "identifiant" unique des conférences CORE
                                match_certain = case_when(distance == 0 ~ 1, n_distinct(id_core) < n() ~ 1, TRUE ~ 0)) #distance 0 entre les chaînes ou même jointure token et score
    # Cas des communications avec même match par score et par token
match_score_token <- enriched_hal %>% filter(match_certain == 1 & nb_matchs > 1) %>% 
    group_by(hal_id, id_core) %>% filter(n() > 1) %>%  # on ne garde que les valeurs dupliquées càd même match score et token
    ungroup() %>% group_by(hal_id) %>% slice(1) %>% 
    mutate(method = "score/token") # qd même match score et token on garde score et on change method = "score/token"
    # Cas des autres communications
enriched_hal <- enriched_hal %>% 
    filter(match_certain == 0 | (match_certain == 1 & nb_matchs == 1)) %>%  # on retire les comm avec même match score et token pour traitement à part
    ungroup() %>% mutate(is_row_delete = case_when(nb_token > 1 & method == "token" ~ 1, # quand multiples tokens on retire token (car correspond aux acronymes doublons dans CORE)
                                                   nb_token > 1 & method == "score" ~ 0, # quand multiples tokens on garde score
                                                   is_score_0 == 1 & method == "score" & distance == 0 ~ 0, # quand match exact via score on garde score
                                                   is_score_0 == 1 & method == "token" ~ 1, # quand match exact via score on retire token
                                                   is_score_0 == 0 & is_token_match == 1 & method == "score" ~ 1, # quand pas de match exact via score, match via token existe; on retire score
                                                   TRUE ~ 0)) %>% filter(is_row_delete == 0) %>% select(-is_row_delete)
    # Remise des 2 dfs dans une seule tble
enriched_hal <- rbind(enriched_hal, match_score_token) %>% 
    select(-c(is_token:id_core)) %>% arrange(hal_id)


# On joint avec les données initiales pour avoir une base avec TOUTES les communications
enriched_hal <- left_join(hal %>% select(title, year, hal_id, booktitle) %>% rename(hal_title = title),
                          enriched_hal %>% select(-c(booktitle, year, hal_title)),
                          by = "hal_id") %>% distinct()


# Stats
a <- enriched_hal %>% filter(!is.na(method))
b <- enriched_hal %>% filter(!is.na(method)) %>% filter(method == "score")
c <- enriched_hal %>% filter(!is.na(method)) %>% filter(method == "token")
d <- enriched_hal %>% filter(!is.na(method)) %>% filter(method == "score/token")


# Export des données enrichies
rio::export(enriched_hal, "../data/enriched_hal.csv")
```


Finalement, nous consolidons les données HAL enrichies via la méthode de score et via la méthode de token dans une même base de données. Lorsqu'un match avec le référentiel CORE a été trouvé avec les 2 méthodes, c'est la méthode du token qui est préférée car selon nos observations, elle est généralement plus fiable. Deux exceptions à cette règle interviennent ; 

- lorsque la méthode de jointure par score est parfaite (la distance entre les deux chaînes de caractères est de 0), celle-ci est alors préférée ;
- lorsque plusieurs conférences sont trouvées via la méthode du token : il s'agit d'un cas où le même acronyme est attribué à plusieurs conférences dans les données CORE, la méthode par score est alors préférée. 

Dans le cas où un match proposé par la méthode score est identique à un match proposé par la méthode token, nous le gardons (en prenant celui du *score* pour garder les informations des distances entre les chaînes de caractères), et nous renommons la méthode *"score/token"*. Pour ces communications, la variable '***match_certain***' prend la valeur *1* signifiant ainsi que la jointure est certaine entre les données du HAL et les données du CORE (avec un intervalle de confiance de 95%). C'est également le cas des communications où le nom de conférence dans HAL est **exactement** le même que dans le référentiel, la distance est alors de 0, donc le match avec les données du CORE est certain. `r enriched_hal %>% filter(match_certain == 1) %>% nrow()` communications sont concernées, sur les `r n_distinct(a$hal_id)` jointures réalisées. 

Ainsi, nous avons au total `r n_distinct(a$hal_id)` communications harmonisées et enrichies par les données CORE, soit `r round(n_distinct(a$hal_id)/nrow(hal)*100, 2)`% des données HAL récupérées par les années de 2018 à 2022. Parmi ces `r n_distinct(a$hal_id)` communications enrichies, `r n_distinct(b$hal_id)` sont finalement issues de la méthode du score (match non exact entre les intitulés de conférence), `r n_distinct(c$hal_id)` de la méthode du token (match exact entre les acronymes de conférence), et `r n_distinct(d$hal_id)` de ces deux dernières. Les `r hal %>% filter(is.na(booktitle)) %>% nrow()` communications n'ayant pas de *'booktitle'*, donc ne pouvant pas être enrichies, sont réintégrées à la base de données. 

<br>

```{r}
# Distribution des distances
graph <- enriched_hal %>% 
    ggplot(aes(x = distance)) +
      geom_histogram(bins = 30L, fill = "#112446", col = "white", size = 1) +
      labs(
        x = "Distance entre les 2 chaînes de caractères",
        y = "Nombre de communications",
        title = "Distribution des distances des noms de conférences contenus dans les \ndonnées HAL et CORE"
      ) +
      theme_classic()
ggplotly(graph)
```

Le graphique ci-dessus représente, pour les communications enrichies par la méthode du *score*, la distribution des distances entre les deux chaînes de caractères des noms de conférence. Celles-ci s'étendent de `r min(enriched_hal$distance, na.rm=T)` (match parfait entre les 2 noms) à `r max(enriched_hal$distance, na.rm=T)`, avec une moyenne de `r round(mean(enriched_hal$distance, na.rm=T), 0)` caractères d'écart. 

**Ci-dessous, les données HAL enrichies du référentiel CORE :**

```{r echo=FALSE, warning=FALSE, error=FALSE}
DT::datatable(enriched_hal, options=list(pageLength=25, searching=T, scrollX='400px'))
```


<br>

----

# 2. Données CORE millésimées

<br>

Cette deuxième partie vise à ajouter le rang de la conférence (de A\* à Unranked, cf. [ce guide](https://drive.google.com/file/d/1q21YeVIEDYyjKJ9WBPXTgbRH_reCnV12/edit)) provenant du référentiel CORE, selon l'année de la communication. Pour cela, les données millésimées du référentiel sont parsées puis importées selon le script [Parse_CORE_millesime.R](https://github.com/datactivist/nettoyage_donnees_HAL/blob/main/scripts/Parse_CORE_millesime.R).

```{r}
# Import des données millésimées
core_histo <- read_csv("../data/core_millesime.csv")

# Préparation de jointure ; on colle l'acronyme au titre pour gérer les 6 conférences qui ont un titre non unique
    # enriched HAL
enriched_hal <- enriched_hal %>% mutate(title_acro = paste(core_title, Acronym))
    # CORE millésimé
core_histo <- core_histo %>% mutate(title_acro = paste(Title, Acronym))

# Jointure des deux bases
enriched_hal_histo <- left_join(enriched_hal, core_histo %>% select(-Title), by = "title_acro", na_matches = "never")

# Filtre pour garder les bons rangs // à l'année de publication de l'archive
enriched_hal_histo <- enriched_hal_histo %>% 
    group_by(hal_id, core_id) %>% mutate(n = n()) %>% #nombre de rangs disponibles
    mutate(to_delete = case_when(n == 1 ~ 0, #quand une seule source dispo on la garde
                                 year == "2018" & source == "CORE2018" ~ 0,
                                 year == "2019" & source == "CORE2018" ~ 0,
                                 year == "2020" & source == "CORE2020" ~ 0,
                                 year == "2021" & source == "CORE2021" ~ 0,
                                 year == "2022" & source == "CORE2021" ~ 0,
                                 TRUE ~ 1),
           is_at_least_one_0 = case_when(any(to_delete == 0) ~ 1,
                                         TRUE ~ 0)) %>% ungroup() %>% 
    mutate(is_row_delete = case_when(is_at_least_one_0 == 1 & to_delete == 1 ~ 1,  TRUE ~ 0)) %>% 
    filter(is_row_delete == 0) %>% 
        # gestion des cas où l'année de publi n'est pas dispo dans l'historique CORE
    mutate(year_millesime = str_extract(source, "(1|2)\\d{3}")) %>% #extraction de l'année depuis la source
    mutate(is_era_delete = case_when(n < 1 & grepl(source, "ERA") == TRUE ~ 1, TRUE ~ 0)) %>% 
    filter(is_era_delete != 1) %>% select(-is_era_delete) %>% #on retire les 'ERA' quand source CORE disponible
    group_by(hal_id, core_id) %>% arrange(desc(year_millesime)) %>% slice(1) #on garde la source la plus récente pour les autres conf

# Mise en forme des données finales
save_enriched_hal_histo <- enriched_hal_histo #sauvegarde pour statistiques
enriched_hal_histo <- enriched_hal_histo %>% 
    select("hal_title","year","hal_id","booktitle","core_title","Acronym.y","source","rank","Primary FoR","core_id","distance","part_similarite","method","match_certain") %>% 
    rename(Acronym = Acronym.y, Source = source, Rank = rank) %>% 
    group_by(hal_id, booktitle) %>% mutate(nb_conf_matches = n()) %>% ungroup()

# Stats
a <- save_enriched_hal_histo %>% group_by(core_id) %>% mutate(is_source_diff = case_when(Source != source ~ 1, TRUE ~ 0)) %>% filter(is_source_diff == 1)
b <- a %>% group_by(core_id) %>% mutate(is_rank_diff = case_when(Rank != rank ~ 1, TRUE ~ 0)) %>% filter(is_rank_diff == 1)

# Export des données
rio::export(enriched_hal_histo, "../data/enriched_hal_millesimees.csv")
```

Les données millésimées des `r n_distinct(core_histo$core_id)` conférences du référentiel CORE est récupéré depuis le portail CORE. Celles-ci sont alors jointes aux données enrichies de la première partie, en appliquant une règle de décision pour déterminer le rang de la conférence au moment de la communication : 

- lorsque l'année de la communication correspond à un millésime du référentiel, le rang de ce millésime est appliqué (*ex: pour une publication de 2018 nous appliquons le rang dont la source est 'CORE2018'*) ;
- lorsque l'année de la communication est 2019 ou 2022, années sans mise à jour du référentiel, nous prenons le rang de l'année précédente (*ex: pour une publication de 2022 nous appliquons le rang dont la source est 'CORE2021'*) ;
- lorsqu'un seul rang est disponible dans les données CORE millésimées, nous le gardons ; 
- dans tous les autres cas, le rang le plus récent est appliqué (excepté lorsque la source la plus récente est '*ERA*' ; c'est alors la source '*CORE*' qui est privilégiée).

Ainsi, le champ *'Source'* est mis à jour en fonction de cette règle, ce qui modifie sa valeur pour `r n_distinct(a$core_id)` communications. Le fait de se référer à un autre millésime change alors la valeur du rang pour `r n_distinct(b$core_id)` d'entre elles.

<br>

----

# Données finales

<br>

Les données finales de cette analyse sont visibles ci-dessous, et disponibles dans le [dossier *data* du repository](https://github.com/datactivist/nettoyage_donnees_HAL/blob/main/data/enriched_hal_millesimees.csv). Elles se composent des champs suivants : 

- ***hal_title*** : le titre de la communication, issu des données HAL ;
- ***year*** : l'année de publication de la communication, issue des données HAL ;
- ***hal_id*** : l'identifiant unique de la communication, issu des données HAL ;
- ***booktitle*** : le titre de la conférence, issu des données HAL ;
- ***core_title*** : le titre de la conférence, issu des données CORE ;
- ***Acronym*** : l'acronyme de la conférence, issu des données CORE ;
- ***Source*** : l'année du rang de la conférence correspondant à l'année de publication de la communication HAL ou l'année la plus récente disponible, issue des données CORE millésimées;
- ***Rank*** : le rang de la conférence correspondant à l'année de publication de la communication HAL ou l'année la plus récente disponible, issu des données CORE millésimées ;
- ***Primary FoR*** : l'identifiant du domaine de recherche (*Field of Research*) de la conférence, issu des données CORE **non millésimées** ;
- ***core_id*** : l'identifiant unique de la conférence, calqué sur le numéro de notice [des données CORE](http://portal.core.edu.au/conf-ranks/1/) ;
- ***distance*** : nombre de caractères non communs aux intitulés de conférence dans les données HAL (*booktitle*) et dans les données CORE (*core_title*), calculé en première partie ;
- ***part_similarite*** : pourcentage de caractères de l'intitulé de conférence HAL se trouvant dans l'intitulé de conférence CORE, calculé en première partie ;
- ***method*** : méthode ayant permis de désambiguïser l'intitulé de la conférence (soit "*score*" soit "*token*"), créée en première partie ;
- ***match_certain*** : variable booléenne indiquant si la jointure entre les données HAL et CORE est certaine (*'1'*) ou non (*'0'*), créée en première partie ;
- ***nb_conf_matches*** : nombre de conférences du référentiel CORE ayant matché avec les données HAL, nécessitant alors un tri manuel au regard des intitulés de conférences ainsi que des acronymes.

<br>

```{r echo=FALSE, warning=FALSE, error=FALSE}
DT::datatable(enriched_hal_histo, options=list(pageLength=25, searching=T, scrollX='400px'))
```

<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>

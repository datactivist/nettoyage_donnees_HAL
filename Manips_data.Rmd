---
title: "Nettoyage et enrichissement des données HAL"
subtitle: "Désambiguïsation des intitulés de conférences"
output:
  html_document:
    #self_contained: false
    theme: paper
    toc: yes
    toc_float: yes
    code_folding: hide
    includes:
      in_header: header.html
      after_body: footer.html
      
knit: (
  function(inputFile, encoding) { 
    
    rmarkdown::render(inputFile, params = "ask",  
      encoding    = encoding,
      output_file = paste0(tools::file_path_sans_ext(inputFile), ".html")) })
---

<style>
body {
text-align: justify;
#background: #f9f9f9;
}
</style> 

```{r setup, include=FALSE}
# Settings summarytools
library(summarytools)
st_options(plain.ascii = FALSE,               # This is very handy in all Rmd documents
           style = "rmarkdown",               # This too
           footnote = NA,                    # Avoids footnotes which would clutter the results
           subtitle.emphasis = FALSE
         # This is a setting to experiment with - according to the theme used, it might improve the headings layout
)
# General settings      
knitr::opts_chunk$set(
	eval = TRUE,
	echo = FALSE,
	fig.align = "center",
	fig.show = "hold",
	message = FALSE,
	warning = FALSE,
	collapse = TRUE,
	results = 'asis', # important dfSummary
	out.width = "100%"
)
```


----

```{r librairies et données, include = FALSE, cache = TRUE}
# Packages nécessaires à l'analyse
packages = c("tidyverse", "summarytools", "threadr", "rvest", "fuzzyjoin", "tm")

## Installation des packages si besoin et chargement des librairies
package.check <- lapply(packages,
  FUN = function(x) {
      if (!require(x, character.only = TRUE)) {
      install.packages(x, dependencies = TRUE)  #remotes::install_github("skgrange/threadr")
      library(x, character.only = TRUE)}})


# Import données 

    # HAL (format bibTex)
hal1 <- read_bibtex("https://api.archives-ouvertes.fr/search/?q=+publicationDateY_i%3A[2018+TO+2020]+AND++(docType_s%3ACOMM)&fq=collCode_s%3AINRIA2&rows=100000&wt=bibtex")
hal2 <- read_bibtex("https://api.archives-ouvertes.fr/search/?q=+publicationDateY_i%3A[2021+TO+2022]+AND++(docType_s%3ACOMM)&fq=collCode_s%3AINRIA2&rows=100000&wt=bibtex")
hal <- rbind(hal1 %>% select(bibtex_key, article_type, title, author, url, editor, series, volume, number, pages, year, month, keywords, pdf, hal_id, hal_version, publisher, doi, organization, booktitle, address ), 
              hal2 %>% select(bibtex_key, article_type, title, author, url, editor, series, volume, number, pages, year, month, keywords, pdf, hal_id, hal_version, publisher, doi, organization, booktitle, address )) %>% 
    distinct() %>% 
    filter(year >= 2018 & year <= 2022) # 10.052 communications

    # CORE (CSV)
core <- purrr::map(
        .x = (as.data.frame(rep(1:45, each = 1)) %>% rename(page = `rep(1:45, each = 1)`))$page,
        .y = data.frame(matrix(ncol = 1, nrow = 1)),
        .f = ~read_html(paste0("http://portal.core.edu.au/conf-ranks/?search=&by=all&source=all&sort=atitle&page=", .x)) %>% html_nodes('body')  %>% html_nodes('table') %>% html_table(dec = ","), 
        .default = NA)
core <- bind_rows(core) %>% rename(title = Title) %>% 
    mutate_all(na_if,"") %>% 
    mutate(core_id = row_number()) # 2.212 conférences
```


**Objectif** : Désambiguïsation des intitulés de conférences renseignés dans les données HAL, en se basant sur le référentiel CORE

**Données à nettoyer** : 

- **Sources des données** : [API HAL](https://api.archives-ouvertes.fr/docs) requêtée sur les références de la collection HAL Inria de type COMM publiées entre 2018 et 2022 
- **Dimensions** : `r ncol(hal)` variables et `r nrow(hal)` individus

**Données de référence** : 

- **Sources des données** : [CORE Conference Portal](http://portal.core.edu.au/conf-ranks/)
- **Dimensions** : `r ncol(core)` variables et `r nrow(core)` individus


---

# Résumé des bases{.tabset}

## HAL

```{r}
dfSummary(hal, style = "grid", graph.magnif = 1, valid.col = FALSE, varnumbers = FALSE, tmp.img.dir = "/tmp", max.distinct.values = 5, headings=FALSE, method = "render")
```

<br>

## CORE

```{r}
dfSummary(core, style = "grid", graph.magnif = 1, valid.col = FALSE, varnumbers = FALSE, tmp.img.dir = "/tmp", max.distinct.values = 5, headings=FALSE, method = "render")
```

<br>

---

# Jointure des bases

<br>

```{r}
# Nettoyage des données
    # HAL
hal_manip <- hal %>% rename(hal_title = title) %>% 
    mutate(booktitle = str_replace_all(booktitle, "[[:punct:]]", " "), # retrait de tous les caractères spéciaux
           booktitle = tolower(booktitle), # minuscules
           booktitle = str_replace(booktitle, "  ", " ")) # retrait des doubles espaces
    # CORE
core_manip <- as.data.frame(gsub("[[:punct:]]", "", as.matrix(core))) %>%  # retrait de tous les caractères spéciaux
    mutate(core_title = tolower(title), # minuscules
           core_title = str_replace(core_title, "  ", " "), # retrait des doubles espaces
           core_acronym = tolower(Acronym), # même chose pour l'acronyme qui servira de colonne de jointure dans un second temps
           core_acronym = str_replace(core_acronym, "  ", " "),
           nb_car_acronym = str_count(Acronym, '\\w+')) # nombre de mots par acronyme
```


Afin de maximiser le matching des intitulés de conférences, un travail de nettoyage et de lémmatisation est préalablement effectué Les intitulés sont ainsi mis en minuscules, sans accents et sans caractères spéciaux. Un match est opéré 2 fois pour faire correspondre les intitulés des données du HAL avec ceux du référentiel CORE. 

Dans un premier temps, les chaînes de caractères formant l'intitulé des conférences HAL sont matchés avec celles du CORE, à partir de quoi on obtient une distance correspondant au nombre de caractères **qui ne sont pas communs** au 2 intitulés (si l'intitulé est exactement le même, la distance sera donc de 0). Cette manipulation est réalisée sur la variable HAL *booktitle*, matchée avec la variable CORE *title* indiquant l'intitulé des conférences.

Dans un deuxième temps ce sont seulement les acronymes qui sont matchés entre les données HAL et le référentiel CORE. Ces derniers sont extraits du nom de conférence disponible dans le champ "*booktitle*" des données HAL. La jointure se fait cette fois sur une base de match **exact**, contrairement aux manipulations réalisées en premier temps sur les intitulés des conférences. Ainsi, lorsque l'acronyme extrait du titre disponible dans les données HAL correspond à l'acronyme CORE, les informations du référentiel sont récupérées et viennent enrichir les données HAL. 

<br>

## Match par distance entre les chaînes de caractères (score)

<br>

La première jointure est réalisée en plafonnant la distance entre les 2 chaînes de caractères à 50 caractères. 
Pour chaque communication HAL, plusieurs conférences sont matchées avec un score de distance allant de 0 à 50. Les données sont ensuite regroupées par communication (*hal_id*), puis, la conférence ayant le nom le plus proche de celui renseigné dans les données HAL est gardée. Dans le cas où 2 noms de conférences ont la même distance par rapport au nom CORE et que celle-ci est la distance minimale, les 2 conférences sont gardées dans les données enrichies, et devront alors faire l'objet d'un traitement manuel.

Les intitulés originaux des communications et conférences des 2 sources de données sont réinjectés dans les données, à la place des intitulés lémmatisés.

Dans la table ci-dessous, les colonnes *hal_title* à *booktitle* proviennent de HAL ; les colonnes *core_title* à *Primary FoR* proviennent de CORE ; les colonnes *distance* et *method* sont générées par l'algorithme de comparaison.

<br>

```{r}
# Match inexact avec distance
enriched_hal_score <- stringdist_left_join(hal_manip %>% select(hal_title, year, hal_id, booktitle) %>% filter(!is.na(booktitle)),
                                    core_manip %>% select(core_title, Acronym, core_id, Source, Rank, `Primary FoR`),
                                    by = c("booktitle" = "core_title"),
                                    max_dist = 50, 
                                    distance_col = "distance") %>% 
    mutate(method = "score") %>% 
    arrange(distance) %>% 
    group_by(hal_id) %>% 
    slice_min(order_by = distance, n = 1) # ne garder que le match le plus proche

# On remet les noms initiaux (avec caractères spéciaux et majuscules)
enriched_hal_score <- enriched_hal_score %>% 
    # Noms des communications et conférences dans HAL
    select(-c(hal_title, booktitle)) %>% 
    left_join(., hal %>% select(title, booktitle, hal_id), by = "hal_id") %>% 
    rename(hal_title = title) %>% 
    # Noms des conférences et acronymes dans CORE
    select(-c(core_title)) %>% mutate(core_id = as.numeric(core_id)) %>% 
    left_join(., core %>% select(title, core_id), by = "core_id") %>% 
    rename(core_title = title) %>% 
    # Mise en forme finale
    select("hal_title","year","hal_id","booktitle","core_title","Acronym","Source","Rank","Primary FoR","distance","method")
```



```{r echo=FALSE, warning=FALSE, error=FALSE}
DT::datatable(enriched_hal_score, options=list(pageLength=25, searching=T, scrollX='400px'))
```

Cette première méthode de jointure non exacte sur les intitulés de conférences a permis d'enrichir `r n_distinct(enriched_hal_score$hal_id)` communications sur `r nrow(hal)`, soit `r round(n_distinct(enriched_hal_score$hal_id) / nrow(hal) *100, 0)`%. Parmi ces jointures, `r enriched_hal_score %>% filter(distance == 0) %>% nrow()` sont exactes, c'est-à-dire que l'intitulé dans les données HAL correspond **exactement** à celui de la conférence dans les données CORE (aux caractères spéciaux et majuscules près). 

<br>

## Match par mot commun aux deux chaines de caractères (token) 

<br>

La deuxième jointure est réalisée en identifiant l'acronyme qui se trouve fréquemment dans l'intitulé de conférence des données HAL, pour le matcher avec les données CORE. Lorsque l'acronyme identifié **se retrouve à l'identique** dans le champ *Acronym* de CORE, alors l'entrée est enrichie du référentiel CORE. L'extraction de l'acronyme est faite de deux manières à partir du champ *booktitle* des données HAL :

* le premier mot est extrait (excepté s'il s'agit d'un des 3 mots suivants : IEEE, ACM, SIAM qui sont des sociétés savantes organisant de nombreuses conférences) ;
* le ou les mots entièrement en majuscules sont extraits ;
* un arbitrage est effectué entre les 2 valeurs récupérées, selon un ensemble de règles implémentées dans le script visible après ces lignes.

Après jointure des acronymes extraits des noms de conférences HAL avec les données du CORE, les données sont réharmonisées avec les bases initiales pour récupérer les intitulés et acronymes non lemmatisés. 

<br>

```{r echo=TRUE}
        #--------- PREMIÈRE PASSE DE JOINTURE TOKEN


# Fonction pour retirer les mots doublons
rem_dup_word <- function(x){
paste(unique(trimws(unlist(strsplit(x,split=" ",fixed=F,perl=T)))),collapse = 
" ")
}

# Extraction de l'acronyme depuis booktitle
hal_manip_token <- hal %>% rowwise() %>% 
    mutate(booktitle = removeWords(booktitle, c("IEEE ", "ACM ", "SIAM ")),
           first_word = word(booktitle, 1), #premier mot du string
           capital_word = rem_dup_word(sapply(str_extract_all(booktitle, "\\b[A-Z]+\\b"), paste, collapse= ' ')), #mots en lettres capitales uniques
           capital_word = gsub("\\W*\\b\\w\\b\\W*", " ", capital_word)) %>% #retirer lettres toutes seules
    mutate_all(na_if, "") %>% 
    mutate(hal_acronym = case_when(is.na(capital_word) ~ first_word,
                                    is.na(first_word) ~ capital_word,
                                    first_word == "In" ~ capital_word,
                                    first_word == capital_word ~ first_word,
                                    str_detect(first_word, "[0-9]") == TRUE ~ capital_word, #qd first_word contient un chiffre
                                    nchar(capital_word) == 1 ~ first_word, #qd 1 seul caractère dans capital_word
                                    grepl('[^[:alnum:]]', first_word) ~ capital_word, #qd first_word contient des caractères sépciaux (hors lettres et digits)
                                    TRUE ~ capital_word)) %>%  
    select(title, booktitle, year, hal_id, hal_acronym) %>% 
    rename(hal_title = title)

# Lémmatisation des acronymes 
hal_manip_token <- hal_manip_token %>%  
    mutate(hal_acronym = str_replace_all(hal_acronym, "[[:punct:]]", " "), # retrait de tous les caractères spéciaux
           hal_acronym = tolower(hal_acronym)) %>%  # minuscules
    mutate(hal_acronym = strsplit(as.character(hal_acronym), " ")) %>% unnest(hal_acronym) %>%  #split par ligne les acronymes multiples
    mutate_all(na_if, "") %>% 
    mutate_all(na_if, " ") %>% 
    filter(hal_acronym != "ieee",
           hal_acronym != "acm")

# Match sur les tokens communs
enriched_hal_token <- hal_manip_token %>% 
    filter(!is.na(hal_acronym)) %>% 
    left_join(., 
              core_manip %>% select(core_title, core_acronym, Acronym, core_id, Source, Rank, `Primary FoR`), 
              by = c("hal_acronym" = "core_acronym")) %>% 
    filter(!is.na(Acronym)) %>% 
    mutate(method = "token") %>% 
    select("hal_title","year","hal_id","booktitle","core_title","Acronym","Source","Rank","Primary FoR","method","core_id")

# On remet les colonnes initiales (non lémmatisés)
enriched_hal_token <- enriched_hal_token %>% 
    # Noms des communications et conférences dans HAL
    select(-c(hal_title, booktitle)) %>% 
    left_join(., hal %>% select(title, booktitle, hal_id), by = "hal_id") %>% 
    rename(hal_title = title) %>% 
    # Noms des conférences et acronymes dans CORE
    select(-c(core_title)) %>% mutate(core_id = as.numeric(core_id)) %>% 
    left_join(., core %>% select(title, core_id), by = "core_id") %>% 
    rename(core_title = title) %>% 
    # Mise en forme finale
    select("hal_title","year","hal_id","booktitle","core_title","Acronym","Source","Rank","Primary FoR","method") %>% 
    mutate(distance = NA_real_, .before = "method") #colonne distance vide pour token avant rbind
```


```{r echo=FALSE, warning=FALSE, error=FALSE}
DT::datatable(enriched_hal_token, options=list(pageLength=25, searching=T, scrollX='400px'))
```


Cette deuxième méthode de jointure exacte par match de l'acronyme CORE, a permis d'enrichir `r n_distinct(enriched_hal_token$hal_id)` communications sur `r nrow(hal)`, dont `r length(setdiff(enriched_hal_token$hal_id, enriched_hal_score$hal_id))` qui n'avaient pas été enrichies par la première méthode de distance entre les chaînes de caractères (score).


<br>


# Données finales enrichies

```{r}
# On remet avec la jointure par distance
enriched_hal <- rbind(enriched_hal_score, enriched_hal_token) %>% distinct() %>%
    group_by(hal_id) %>% mutate(is_token_match = case_when(any(method == "token") ~ 1, TRUE ~ 0)) %>% 
    ungroup() %>% mutate(is_row_score = case_when(is_token_match == 1 & method == "score" ~ 1, TRUE ~ 0)) %>% 
    filter(is_row_score == 0) %>% select(-c(is_token_match, is_row_score))

# On joint avec les données initiales pour avoir une base avec TOUTES les communications
enriched_hal <- left_join(hal %>% select(title, year, hal_id, booktitle) %>% rename(hal_title = title),
                  enriched_hal %>% select(-c(booktitle, year, hal_title)),
                  by = "hal_id")

# Stats
a <- enriched_hal %>% filter(!is.na(method))
b <- enriched_hal %>% filter(!is.na(method)) %>% filter(method == "score")
c <- enriched_hal %>% filter(!is.na(method)) %>% filter(method == "token")

# Export des données enrichies
rio::export(enriched_hal, "enriched_hal.csv")
```


Finalement, nous consolidons les données HAL enrichies via la méthode de score et via la méthode de token dans une même base de données. Lorsqu'un match avec le référentiel CORE a été trouvé avec les 2 méthodes, c'est la méthode du token qui est préférée car selon nos observations, elle est généralement plus fiable. Ainsi, nous avons au total `r n_distinct(a$hal_id)` communications harmonisées et enrichies par les données CORE, soit `r round(n_distinct(a$hal_id)/nrow(hal)*100, 0)`% des données HAL récupérées par les années de 2018 à 2022. Parmi ces `r n_distinct(a$hal_id)` communications enrichies, `r n_distinct(b$hal_id)` sont finalement issues de la méthode du score (match non exact entre les intitulés de conférence) et `r n_distinct(c$hal_id)` de la méthode du token (match exact entre les acronymes de conférence).


```{r echo=FALSE, warning=FALSE, error=FALSE}
DT::datatable(enriched_hal, options=list(pageLength=25, searching=T, scrollX='400px'))
```

<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>